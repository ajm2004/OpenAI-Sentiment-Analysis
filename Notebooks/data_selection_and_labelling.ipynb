{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA SELECTION AND LABELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers sentence-transformers vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jonathan\\Desktop\\F20AA - Applied Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SEMANTIC SEARCH WITH SENTENCE TRANSFORMERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filtering, there ~54k records (~9k posts, ~47k comments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this section is to select the most relevant records that express sentiments about OpenAI, and filter out low quality data. It will enable us to produce a high quality dataset for company reputation analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to using embedding-based semantic search, we experimented with TF-IDF-based retrieval, to find the most relevant records, i.e, the records with the highest cosine similarity to a given query. However, upon manually labellign ~450 of the most relevant records selected using TF-IDF, we found that ~41% of the records were irrelevant, i.e, they express no positive/negative/neutral sentiment about OpenAI.\n",
    "\n",
    "This is primarily because term-based vectorization methods like TF-IDF do not represent the semantic meaning of the data. Therefore, we decided to experiment with using embedding models with the Sentence Transformers library, which are specialized for conducting semantic retrieval of the most relevant data points, using cosine similarity.\n",
    "\n",
    "You can find our experiments with retrieval using TF-IDF here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are utilizing the msmarco-distilbert-cos-v5 model as the embedding model for the following reasons:\n",
    "1. As visualized during exploratory data analysis, our \"passages\" (comments and posts) are generally longer than the length of the queries we will be using for retrieval (see below). Therefore, we require a model for asymmetric semantic search (where the query is generally shorter in length than the passages to be retrieved). The [Sentence Transformer documentation](https://www.sbert.net/examples/applications/semantic-search/README.html#symmetric-vs-asymmetric-semantic-search) recommends models trained on the MS-MARCO information retrieval dataset, for asymmetric semantic search. \n",
    "\n",
    "2. DistilBERT is a smaller, lighter version of BERT that maintains most of the original performance. It is used as the backbone of this embedding model. Therefore, it will be efficient and quick to retrieve relevant examples from our dataset. \n",
    "\n",
    "3. The model performs relatively well compared to other Sentence Transformers on various [information retrieval benchmarks](https://www.sbert.net/docs/pretrained-models/msmarco-v5.html#performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1e419b1a6a42238ca0fcd70b1923ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--sentence-transformers--msmarco-distilbert-cos-v5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883daaa73f1c4928aa028bcca689bf01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831c90be09f44ed8b3e9b8937acd9a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683aae70bb8f4595941277c9a5897146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b6eee108bc411b9f3c0a953705154e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/545 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f4a85a6e874be78d1d675795a4b9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c35b829cc448a395934a11ebb2274c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/319 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee77fe75e80457581371437f53e60ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d7412331934bb8b4e818e4301ee02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13dc1000f4b4a81baab190abeb389b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625bb0f9bebb4024a976d1d557d18132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer(\"msmarco-distilbert-cos-v5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple search queries, corresponding to each sentiment label, to help\n",
    "# retrieve a balanced dataset\n",
    "queries = [\"What do users think about OpenAI’s ChatGPT, DALL·E, and other AI tools?\",\n",
    "           \"How well do OpenAI’s models perform according to user reviews?\",\n",
    "           \"Comparison of OpenAI's products and other competitors based on user reviews\",\n",
    "           \"Criticism and complaints about OpenAI’s products in user reviews\",\n",
    "           \"Customer satisfaction and positive experiences with OpenAI products\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the text column of filtered_data as a list \n",
    "reviews = filtered_data[\"text\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for the queries\n",
    "query_embeddings = embedding_model.encode(queries, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for the reviews\n",
    "review_embeddings = embedding_model.encode(reviews[:15], convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cosine similarity search between the queries and reviews embeddings, and retrieve the top 5000 most similar reviews, for each query\n",
    "retrieved_reviews = util.semantic_search(query_embeddings, review_embeddings, top_k = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'corpus_id': 6, 'score': 0.44747495651245117},\n",
       "  {'corpus_id': 10, 'score': 0.21365712583065033},\n",
       "  {'corpus_id': 7, 'score': 0.20477834343910217},\n",
       "  {'corpus_id': 9, 'score': 0.1452714502811432},\n",
       "  {'corpus_id': 14, 'score': 0.13351130485534668},\n",
       "  {'corpus_id': 1, 'score': 0.1301075518131256},\n",
       "  {'corpus_id': 2, 'score': 0.12205448001623154},\n",
       "  {'corpus_id': 8, 'score': 0.09173666685819626},\n",
       "  {'corpus_id': 3, 'score': 0.0722956731915474},\n",
       "  {'corpus_id': 13, 'score': 0.06409384310245514},\n",
       "  {'corpus_id': 12, 'score': 0.06230776011943817},\n",
       "  {'corpus_id': 4, 'score': 0.038176536560058594},\n",
       "  {'corpus_id': 11, 'score': 0.01644682139158249},\n",
       "  {'corpus_id': 5, 'score': 0.01644682139158249},\n",
       "  {'corpus_id': 0, 'score': 0.0032186005264520645}],\n",
       " [{'corpus_id': 6, 'score': 0.45526471734046936},\n",
       "  {'corpus_id': 7, 'score': 0.2362341433763504},\n",
       "  {'corpus_id': 10, 'score': 0.21888545155525208},\n",
       "  {'corpus_id': 14, 'score': 0.1883079707622528},\n",
       "  {'corpus_id': 9, 'score': 0.11210362613201141},\n",
       "  {'corpus_id': 13, 'score': 0.10353273898363113},\n",
       "  {'corpus_id': 0, 'score': 0.09966543316841125},\n",
       "  {'corpus_id': 3, 'score': 0.07937613874673843},\n",
       "  {'corpus_id': 12, 'score': 0.07841020822525024},\n",
       "  {'corpus_id': 2, 'score': 0.07838406413793564},\n",
       "  {'corpus_id': 1, 'score': 0.0615517720580101},\n",
       "  {'corpus_id': 8, 'score': 0.043631576001644135},\n",
       "  {'corpus_id': 4, 'score': -0.000753551721572876},\n",
       "  {'corpus_id': 5, 'score': -0.025037474930286407},\n",
       "  {'corpus_id': 11, 'score': -0.025037474930286407}],\n",
       " [{'corpus_id': 6, 'score': 0.5170033574104309},\n",
       "  {'corpus_id': 10, 'score': 0.2575347423553467},\n",
       "  {'corpus_id': 7, 'score': 0.22177067399024963},\n",
       "  {'corpus_id': 13, 'score': 0.17739950120449066},\n",
       "  {'corpus_id': 2, 'score': 0.1281353235244751},\n",
       "  {'corpus_id': 14, 'score': 0.11806933581829071},\n",
       "  {'corpus_id': 9, 'score': 0.11208007484674454},\n",
       "  {'corpus_id': 0, 'score': 0.080921471118927},\n",
       "  {'corpus_id': 1, 'score': 0.07159635424613953},\n",
       "  {'corpus_id': 4, 'score': 0.0715150386095047},\n",
       "  {'corpus_id': 3, 'score': 0.06832493841648102},\n",
       "  {'corpus_id': 12, 'score': 0.06614240258932114},\n",
       "  {'corpus_id': 8, 'score': 0.035653550177812576},\n",
       "  {'corpus_id': 5, 'score': 0.03333446383476257},\n",
       "  {'corpus_id': 11, 'score': 0.03333446383476257}]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the highest score for each unique id\n",
    "# from the results of all the queries\n",
    "unique_reviews = {}\n",
    "\n",
    "for review_list in retrieved_reviews:\n",
    "    for review in review_list:\n",
    "        corpus_id = review['corpus_id']\n",
    "        score = review['score']\n",
    "        if corpus_id not in unique_reviews or score > unique_reviews[corpus_id]:\n",
    "            unique_reviews[corpus_id] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the filtered_data DataFrame to include a new column for the cosine similarity score\n",
    "# for each unique id\n",
    "filtered_data['cosine_similarity'] = filtered_data['text'].apply(lambda x: unique_reviews.get(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where cosine similarity is 0\n",
    "filtered_data = filtered_data[filtered_data['cosine_similarity'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the DataFrame by cosine similarity in descending order\n",
    "filtered_data = filtered_data.sort_values(by='cosine_similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "post_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subreddit",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "post_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "post_body",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "number_of_comments",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "readable_datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "post_author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "number_of_upvotes",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "query",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "comment_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "comment_body",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "comment_author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cosine_similarity",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "dc1aa053-c89a-44e1-9573-440d76fc8e3f",
       "rows": [],
       "shape": {
        "columns": 14,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_body</th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>readable_datetime</th>\n",
       "      <th>post_author</th>\n",
       "      <th>number_of_upvotes</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [post_id, subreddit, post_title, post_body, number_of_comments, readable_datetime, post_author, number_of_upvotes, query, text, comment_id, comment_body, comment_author, cosine_similarity]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the selected data\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "number_of_comments",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "readable_datetime",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "number_of_upvotes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cosine_similarity",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "62b6cb20-20a5-4e51-b220-344afca15990",
       "rows": [
        [
         "count",
         "0.0",
         "0",
         "0.0",
         "0.0"
        ],
        [
         "mean",
         null,
         null,
         null,
         null
        ],
        [
         "min",
         null,
         null,
         null,
         null
        ],
        [
         "25%",
         null,
         null,
         null,
         null
        ],
        [
         "50%",
         null,
         null,
         null,
         null
        ],
        [
         "75%",
         null,
         null,
         null,
         null
        ],
        [
         "max",
         null,
         null,
         null,
         null
        ],
        [
         "std",
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>readable_datetime</th>\n",
       "      <th>number_of_upvotes</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_comments readable_datetime  number_of_upvotes  \\\n",
       "count                 0.0                 0                0.0   \n",
       "mean                  NaN               NaT                NaN   \n",
       "min                   NaN               NaT                NaN   \n",
       "25%                   NaN               NaT                NaN   \n",
       "50%                   NaN               NaT                NaN   \n",
       "75%                   NaN               NaT                NaN   \n",
       "max                   NaN               NaT                NaN   \n",
       "std                   NaN               NaN                NaN   \n",
       "\n",
       "       cosine_similarity  \n",
       "count                0.0  \n",
       "mean                 NaN  \n",
       "min                  NaN  \n",
       "25%                  NaN  \n",
       "50%                  NaN  \n",
       "75%                  NaN  \n",
       "max                  NaN  \n",
       "std                  NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the retrieved data to a new CSV file\n",
    "filtered_data.to_csv('../Data/selected_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LABELLING THE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling with RoBERTa based sentiment analysis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"text-classification\", \n",
    "                              model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "                              device=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = filtered_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the text column of selected_data as a list\n",
    "reviews = selected_data[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sentiment of the each of the reviews\n",
    "kwargs = {'padding':True,'truncation':True,'max_length':512}\n",
    "results = sentiment_pipeline(reviews, **kwargs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data[\"roberta_label\"] = [res[\"label\"] for res in results]\n",
    "selected_data[\"roberta_score\"] = [res[\"score\"] for res in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling with VADER (Lexicon and Rule-Based Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER was selected as it is specialized for sentiment analysis on social media comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentAnalyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_label, vader_score = [], []\n",
    "\n",
    "for review in reviews:\n",
    "    # Calculate the sentiment of the review using VADER\n",
    "    sentiment = sentimentAnalyzer.polarity_scores(review)\n",
    "    vader_score.append(sentiment[\"compound\"])\n",
    "    \n",
    "    if sentiment[\"compound\"] >= 0.07:\n",
    "        vader_label.append(\"positive\")\n",
    "    elif sentiment[\"compound\"] <= -0.07:\n",
    "        vader_label.append(\"negative\")\n",
    "    else:\n",
    "        vader_label.append(\"neutral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the VADER sentiment label and score to the selected_data DataFrame\n",
    "selected_data[\"vader_label\"] = vader_label\n",
    "selected_data[\"vader_score\"] = vader_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "post_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subreddit",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "post_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "post_body",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "number_of_comments",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "readable_datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "post_author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "number_of_upvotes",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "query",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "comment_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "comment_body",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "comment_author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cosine_similarity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "roberta_label",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roberta_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vader_label",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vader_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c9d30dcc-56dd-4577-a386-2c9d30b55d4e",
       "rows": [],
       "shape": {
        "columns": 18,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_body</th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>readable_datetime</th>\n",
       "      <th>post_author</th>\n",
       "      <th>number_of_upvotes</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>roberta_label</th>\n",
       "      <th>roberta_score</th>\n",
       "      <th>vader_label</th>\n",
       "      <th>vader_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [post_id, subreddit, post_title, post_body, number_of_comments, readable_datetime, post_author, number_of_upvotes, query, text, comment_id, comment_body, comment_author, cosine_similarity, roberta_label, roberta_score, vader_label, vader_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the selected_data DataFrame\n",
    "selected_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the selected_data DataFrame to a new CSV file\n",
    "selected_data.to_csv('../Data/labelled_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
