{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"text-classification\", \n",
    "                              model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "                              device=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the csv file\n",
    "df = pd.read_csv(r\"../Data/similarity_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a seperate dataframe containing only records where comment_id is empty\n",
    "df_posts = df[df[\"comment_id\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows without a post_body: 22432\n"
     ]
    }
   ],
   "source": [
    "# Check if the post_body has any empty values (these rows correspond to comments)\n",
    "print(\"Number of rows without a post_body:\", df[\"post_body\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comment rows, extract the corresponding post_body from the posts_df and add it to the df\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isnull(row[\"post_body\"]):\n",
    "        post = df_posts[df_posts[\"post_id\"] == row[\"post_id\"]][\"post_body\"]\n",
    "        df.at[index, \"post_body\"] = str(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows without a post_body: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if the post_body has any empty values (these should all be filled now)\n",
    "print(\"Number of rows without a post_body:\", df[\"post_body\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the post and comment text into a single column\n",
    "df[\"combined_text\"] = \"Post:\" + df[\"post_body\"] + \"\\n Comment:\" + df[\"comment_body\"]\n",
    "df[\"combined_text\"] = df[\"combined_text\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"combined_text\"] = df[\"combined_text\"].apply(lambda x: x.replace(\"None\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a graph to see the siz of text in combined_text\n",
    "df[\"combined_text\"].str.len().hist(bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since roberta has a context window of 512 tokens (approx 2048 chars), drop rows with text > 2048 chars\n",
    "df = df[df[\"combined_text\"].str.len() < 2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the sentiment of the combined text\u001b[39;00m\n\u001b[0;32m      2\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m512\u001b[39m}\n\u001b[1;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msentiment_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcombined_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:159\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,)\n\u001b[1;32m--> 159\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1343\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1340\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   1341\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1342\u001b[0m     )\n\u001b[1;32m-> 1343\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m   1345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1269\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1268\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1269\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1270\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:190\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    189\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1320\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1320\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1332\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:976\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    974\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 976\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    989\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:631\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    620\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    621\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    622\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    628\u001b[0m         output_attentions,\n\u001b[0;32m    629\u001b[0m     )\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:562\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    559\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    560\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 562\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\transformers\\pytorch_utils.py:260\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:574\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m--> 574\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:472\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 472\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Text Analytics\\CW1\\F20AA_Grp5\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Calculate the sentiment of the combined text\n",
    "kwargs = {'padding':True,'truncation':True,'max_length':512}\n",
    "results = sentiment_pipeline(df[\"combined_text\"].tolist(), **kwargs) \n",
    "df[\"label_1\"] = [res[\"label\"] for res in results]\n",
    "df[\"score_1\"] = [res[\"score\"] for res in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file\n",
    "df.to_csv(r\"../Data/labelled_data_1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
