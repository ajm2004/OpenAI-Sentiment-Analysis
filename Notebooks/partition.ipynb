{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data has 100 rows.\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv(\"../Data/labelling-round_1.csv\")\n",
    "print(f\"Original data has {len(df)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Prepare list containers for splits (one list per file)\n",
    "split_dfs = [[] for _ in range(4)]\n",
    "\n",
    "# Process each label group separately\n",
    "for label, group in df.groupby(\"roberta_label\"):\n",
    "    # Shuffle the rows within the group for randomness (set random_state for reproducibility)\n",
    "    group_shuffled = group.sample(frac=1, random_state=42)\n",
    "    # Split the group into 4 parts as evenly as possible\n",
    "    group_splits = np.array_split(group_shuffled, 4)\n",
    "    \n",
    "    # Append each split to its corresponding container\n",
    "    for i, split in enumerate(group_splits):\n",
    "        split_dfs[i].append(split)\n",
    "\n",
    "# Concatenate the splits for each of the 4 sets\n",
    "final_splits = [pd.concat(parts) for parts in split_dfs]\n",
    "\n",
    "# (Optional) Shuffle each final split to mix rows from different labels\n",
    "final_splits = [split.sample(frac=1, random_state=42).reset_index(drop=True) for split in final_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified splitting complete. Each split maintains the original distribution.\n"
     ]
    }
   ],
   "source": [
    "# Verify that all rows are included\n",
    "total_rows = sum(len(split) for split in final_splits)\n",
    "assert total_rows == len(df), \"Row count mismatch after splitting!\"\n",
    "print(\"Stratified splitting complete. Each split maintains the original distribution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 26 rows to labelling-round_1_JJ.csv\n",
      "Saved 26 rows to labelling-round_1_AG.csv\n",
      "Saved 25 rows to labelling-round_1_AJ.csv\n",
      "Saved 23 rows to labelling-round_1_ST.csv\n",
      "All files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "output_files = [\n",
    "    \"labelling-round_1_JJ.csv\",\n",
    "    \"labelling-round_1_AG.csv\",\n",
    "    \"labelling-round_1_AJ.csv\",\n",
    "    \"labelling-round_1_ST.csv\"\n",
    "]\n",
    "\n",
    "# Save each split to its corresponding CSV file without modifying the content/fields\n",
    "for file, split_df in zip(output_files, final_splits):\n",
    "    split_df.to_csv(file, index=False)\n",
    "    print(f\"Saved {len(split_df)} rows to {file}\")\n",
    "\n",
    "print(\"All files saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole Balanced Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../Data/labelled_data_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records after filtering: 4712\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows where similarity <= 0\n",
    "df_filtered = df[df['similarity'] > 0]\n",
    "\n",
    "# Print the number of records left\n",
    "print(f\"Number of records after filtering: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in label_1: ['negative' 'neutral' 'positive']\n"
     ]
    }
   ],
   "source": [
    "# Print the unique classes in 'label_1'\n",
    "print(\"Unique classes in label_1:\", df_filtered['label_1'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts after filtering:\n",
      " label_1\n",
      "neutral     2169\n",
      "negative    1741\n",
      "positive     802\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure we have at least 200 samples per class\n",
    "class_counts = df_filtered['label_1'].value_counts()\n",
    "print(\"Class counts after filtering:\\n\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27624\\114901151.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_balanced = df_filtered.groupby('label_1').apply(lambda x: x.sample(n=200, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Sample 200 from each class\n",
    "df_balanced = df_filtered.groupby('label_1').apply(lambda x: x.sample(n=200, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27624\\1999862780.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_subset = df_balanced.groupby('label_1').apply(lambda x: x.iloc[i*50:(i+1)*50]).reset_index(drop=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27624\\1999862780.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_subset = df_balanced.groupby('label_1').apply(lambda x: x.iloc[i*50:(i+1)*50]).reset_index(drop=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27624\\1999862780.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_subset = df_balanced.groupby('label_1').apply(lambda x: x.iloc[i*50:(i+1)*50]).reset_index(drop=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27624\\1999862780.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_subset = df_balanced.groupby('label_1').apply(lambda x: x.iloc[i*50:(i+1)*50]).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split into four equal sets of 150 records each (50 per class)\n",
    "dfs = []\n",
    "for i in range(4):\n",
    "    df_subset = df_balanced.groupby('label_1').apply(lambda x: x.iloc[i*50:(i+1)*50]).reset_index(drop=True)\n",
    "    dfs.append(df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../Data/manual_labelSet_AM.csv with 150 records.\n",
      "Saved ../Data/manual_labelSet_JJ.csv with 150 records.\n",
      "Saved ../Data/manual_labelSet_ST.csv with 150 records.\n",
      "Saved ../Data/manual_labelSet_AG.csv with 150 records.\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# Define file names\n",
    "file_names = [\"../Data/manual_labelSet_AM.csv\", \"../Data/manual_labelSet_JJ.csv\", \"../Data/manual_labelSet_ST.csv\", \"../Data/manual_labelSet_AG.csv\"]\n",
    "\n",
    "# Save each subset as a CSV file\n",
    "for df_part, name in zip(dfs, file_names):\n",
    "    df_part.to_csv(name, index=False)\n",
    "    print(f\"Saved {name} with {len(df_part)} records.\")\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
