{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABELLING - ACTIVE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (4.48.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: datasets in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Labelling and Finetuning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function that labels the data with the provided model\n",
    "and saves the labeled data to a csv file. Additionally,\n",
    "it saves 100 rows with the lowest RoBERTa confidence scores\n",
    "to a new CSV file.\n",
    "\n",
    "Params:\n",
    "model - the model to be used for sentiment analysis\n",
    "tokenizer - the tokenizer to be used for sentiment analysis\n",
    "dataset - dataframe containing the entire dataset\n",
    "round - active learning round\n",
    "'''\n",
    "def label_data(model, tokenizer, dataset, round):\n",
    "  # Initialize the sentiment analysis pipeline\n",
    "  sentiment_pipeline = pipeline(\"text-classification\", \n",
    "                                model=model,\n",
    "                                tokenizer=tokenizer,\n",
    "                                device=0) \n",
    "  \n",
    "  # Extract the text column of selected_data as a list\n",
    "  reviews = dataset[\"text\"].tolist()\n",
    "    \n",
    "  # Calculate the sentiment of the each of the reviews\n",
    "  print(f\"\\nRound {round} - Automated Labelling \")\n",
    "  print(\"Predicting sentiment labels of data...\")\n",
    "\n",
    "  kwargs = {'padding':True,'truncation':True,'max_length':512}\n",
    "  results = sentiment_pipeline(reviews, **kwargs) \n",
    "\n",
    "  print(\"Sentiment labels predicted.\")\n",
    "  print(\"Saving labeled data to a csv files...\")\n",
    "\n",
    "  # Add the sentiment and score to the selected_data DataFrame\n",
    "  label2id = {\"positive\": 1, \"negative\": -1, \"neutral\": 0}\n",
    "  dataset[\"roberta_label\"] = [label2id[res[\"label\"]] for res in results]\n",
    "  dataset[\"roberta_score\"] = [res[\"score\"] for res in results]\n",
    "\n",
    "  # Save the labeled data to a csv file\n",
    "  dataset.to_csv(f'../Data/Labelling/round{round}_roberta_labelled_all_data.csv', index=False)\n",
    "\n",
    "  # Save 100 rows with the lowest RoBERTa confidence scores to a new CSV file\n",
    "  df_low_confidence = dataset.nsmallest(100, 'roberta_score')\n",
    "  df_low_confidence.to_csv(f'../Data/Labelling/round{round}_roberta_labelled_low_confidence.csv', index=False)\n",
    "  \n",
    "  print(f\"Completed Round {round} - Automated Labeling\")\n",
    "\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, process and tokenize the manual data for each round\n",
    "def process_manual_data(tokenizer, round):\n",
    "  # Wait till the manually labelled data for the round is ready\n",
    "  ready = input(f\"Press 'y' when the manually labelled data for round {round} is added to the Data/Labelling/Manual folder: \")\n",
    "  \n",
    "  while ready.lower()!= 'y':\n",
    "    print(\"Please add the manually labelled data to the Data/Labelling/Manual folder.\")\n",
    "    ready = input(f\"Press 'y' when the manual data for round {round} is added to the Manual folder: \")\n",
    "\n",
    "  # Load the manual data for the round, and all the rounds before it (to retain previously learnt patterns)\n",
    "  manual_data = pd.read_csv(f'../Data/Labelling/Manual/round{round}_manual_low_confidence.csv')\n",
    "  for i in range(1, round):\n",
    "    round_data = pd.read_csv(f'../Data/Labelling/Manual/round{i}_manual_low_confidence.csv')\n",
    "    manual_data = pd.concat([manual_data, round_data], ignore_index=True)\n",
    "\n",
    "  # Drop all columns except the text and the manual label\n",
    "  manual_data.drop(columns=[col for col in manual_data.columns if col not in ['text', 'manual_label']], inplace=True)\n",
    "\n",
    "  # Drop the duplicates from the manual data, keeping the first occurence (latest label)\n",
    "  manual_data.drop_duplicates(subset=['text'], keep='first', inplace=True)\n",
    "\n",
    "  # Drop the rows which are NaN, or contain '2' values in the manual_label column (rows marked irrelevant during manual labelling)\n",
    "  manual_data = manual_data[manual_data['manual_label'] != 2].dropna()\n",
    "\n",
    "  # Convert to Dataset object\n",
    "  manual_data = Dataset.from_pandas(manual_data)\n",
    "  \n",
    "  # Tokenize the data using the model's tokenizer\n",
    "  manual_data_tokenized = manual_data.map(\n",
    "    lambda instance: tokenizer(instance[\"text\"], truncation=True, max_length=512),\n",
    "    batched=True\n",
    "  )\n",
    "\n",
    "  print(f\"Round {round} - Manual data loaded and processed.\")\n",
    "\n",
    "\n",
    "  return manual_data_tokenized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://huggingface.co/learn/nlp-course/en/chapter3/3?fw=pt\n",
    "def finetune(model, train_data, tokenizer, round):\n",
    "\n",
    "  # Define a data collator object for dynamic padding (padding to the maximum length of the batch)\n",
    "  data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
    "\n",
    "  # Configure the training arguments\n",
    "  training_arguments = TrainingArguments(\n",
    "    output_dir = f'../Models/round{round}_finetuned_model_checkpoints/',\n",
    "    num_train_epochs = 3\n",
    "    )\n",
    "  \n",
    "  trainer = Trainer(\n",
    "    model,\n",
    "    training_arguments,\n",
    "    train_dataset = train_data,\n",
    "    data_collator = data_collator,\n",
    "    tokenizer = tokenizer,\n",
    "  )\n",
    "\n",
    "  # TODO:\n",
    "  # Rename labels from 1, -1, 0 to positive, negative, neutral\n",
    "  # Create a validation set, add compute_metrics\n",
    "\n",
    "  trainer.train()\n",
    "  trainer.save_model(f'../Models/round{round}_finetuned_model')\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Active Learning Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Active learning allows us to manually label the most informative parts of the dataset that confuses the model the most. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to conduct one round of active learning\n",
    "def active_learning(model, tokenizer, dataset, rounds = 5):\n",
    "  \n",
    "  for round in range(1, rounds+1):\n",
    "    print (f\"Round {round} of Active Learning\")\n",
    "    # 1. Using the model, automatically label the entire dataset\n",
    "    label_data(model = model, \n",
    "              df = dataset, \n",
    "              tokenizer = tokenizer,\n",
    "              round = round)\n",
    "    \n",
    "    # 2. Load the manually labeled data, including the newly labeled data from the previous round\n",
    "    train_data = process_manual_data(tokenizer = tokenizer,\n",
    "                                     round = round) \n",
    "    \n",
    "    # 3. Fine-tune the model on the manually labeled data\n",
    "    model = finetune(model = model, \n",
    "                     train_data = train_data,\n",
    "                     tokenizer = tokenizer,\n",
    "                     round = round)\n",
    "        \n",
    "    print (f\"Completed Round {round} of Active Learning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "dataset = pd.read_csv('../Data/selected_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained model and its tokenizer from Hugging Face\n",
    "pretrained_model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct active learning\n",
    "active_learning(model, tokenizer, dataset, round = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Validation Set from previously labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_manual_label = pd.read_csv(r'..\\Data\\Archived\\labelled_data_manual_tfidf_transformer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dataset = pd.read_csv(r'..\\Data\\selected_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop from old manual label, any rows that have 4 in m_label_1\n",
    "old_manual_label = old_manual_label[old_manual_label['m_label_1'] != 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>number_of_upvotes</th>\n",
       "      <th>similarity</th>\n",
       "      <th>score_1</th>\n",
       "      <th>m_label_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>150.951493</td>\n",
       "      <td>192.119403</td>\n",
       "      <td>0.287343</td>\n",
       "      <td>0.726031</td>\n",
       "      <td>-0.033582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>386.466323</td>\n",
       "      <td>918.963661</td>\n",
       "      <td>0.121697</td>\n",
       "      <td>0.151392</td>\n",
       "      <td>0.831716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-19.000000</td>\n",
       "      <td>0.101015</td>\n",
       "      <td>0.385341</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.191583</td>\n",
       "      <td>0.595328</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.747033</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>140.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.859085</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3958.000000</td>\n",
       "      <td>8057.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.975497</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_comments  number_of_upvotes  similarity     score_1  \\\n",
       "count          268.000000         268.000000  268.000000  268.000000   \n",
       "mean           150.951493         192.119403    0.287343    0.726031   \n",
       "std            386.466323         918.963661    0.121697    0.151392   \n",
       "min              0.000000         -19.000000    0.101015    0.385341   \n",
       "25%             11.000000           2.000000    0.191583    0.595328   \n",
       "50%             46.000000           7.000000    0.258199    0.747033   \n",
       "75%            140.500000          45.000000    0.353553    0.859085   \n",
       "max           3958.000000        8057.000000    0.707107    0.975497   \n",
       "\n",
       "        m_label_1  \n",
       "count  268.000000  \n",
       "mean    -0.033582  \n",
       "std      0.831716  \n",
       "min     -1.000000  \n",
       "25%     -1.000000  \n",
       "50%      0.000000  \n",
       "75%      1.000000  \n",
       "max      1.000000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_manual_label.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows from old_manual_label that are present in selected_dataset(based on post_id and comment_id)\n",
    "old_manual_label['post_id_comment_id'] = old_manual_label['post_id'].astype(str) + old_manual_label['comment_id'].astype(str)\n",
    "selected_dataset['post_id_comment_id'] = selected_dataset['post_id'].astype(str) + selected_dataset['comment_id'].astype(str)\n",
    "old_manual_label = old_manual_label[~old_manual_label['post_id_comment_id'].isin(selected_dataset['post_id_comment_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>number_of_upvotes</th>\n",
       "      <th>similarity</th>\n",
       "      <th>score_1</th>\n",
       "      <th>m_label_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>132.809045</td>\n",
       "      <td>136.396985</td>\n",
       "      <td>0.287043</td>\n",
       "      <td>0.722433</td>\n",
       "      <td>-0.025126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>309.480069</td>\n",
       "      <td>703.868178</td>\n",
       "      <td>0.123452</td>\n",
       "      <td>0.150289</td>\n",
       "      <td>0.825339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-19.000000</td>\n",
       "      <td>0.101015</td>\n",
       "      <td>0.385341</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.596950</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.741390</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.855132</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3039.000000</td>\n",
       "      <td>7595.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.975497</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_comments  number_of_upvotes  similarity     score_1  \\\n",
       "count          199.000000         199.000000  199.000000  199.000000   \n",
       "mean           132.809045         136.396985    0.287043    0.722433   \n",
       "std            309.480069         703.868178    0.123452    0.150289   \n",
       "min              0.000000         -19.000000    0.101015    0.385341   \n",
       "25%             11.000000           2.000000    0.179605    0.596950   \n",
       "50%             47.000000           7.000000    0.258199    0.741390   \n",
       "75%            125.000000          39.000000    0.377964    0.855132   \n",
       "max           3039.000000        7595.000000    0.707107    0.975497   \n",
       "\n",
       "        m_label_1  \n",
       "count  199.000000  \n",
       "mean    -0.025126  \n",
       "std      0.825339  \n",
       "min     -1.000000  \n",
       "25%     -1.000000  \n",
       "50%      0.000000  \n",
       "75%      1.000000  \n",
       "max      1.000000  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_manual_label.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Cleaned Text, similarity, label_1, score_1, similarity, and post_id_comment_id columns\n",
    "old_manual_label.drop(columns=['Cleaned Text', 'similarity', 'label_1', 'score_1', 'post_id_comment_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the text field, remove the word None that appears at the end of the text\n",
    "old_manual_label['text'] = old_manual_label['text'].str.replace('None$', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_body</th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>readable_datetime</th>\n",
       "      <th>post_author</th>\n",
       "      <th>number_of_upvotes</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>m_label_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1icahc2</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>Why does deepseek keep calling itself chatgpt</td>\n",
       "      <td>well I know identity doesn’t matter,</td>\n",
       "      <td>116</td>\n",
       "      <td>2025-01-28 23:50:33</td>\n",
       "      <td>baskerville_clan</td>\n",
       "      <td>166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why does deepseek keep calling itself chatgpt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ib7xft</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>Please bro stop using the free better alternat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>860</td>\n",
       "      <td>2025-01-27 16:40:08</td>\n",
       "      <td>analgerianabroad</td>\n",
       "      <td>124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Faking\" low cost is literally what ChatGPT wa...</td>\n",
       "      <td>m9h65nu</td>\n",
       "      <td>\"Faking\" low cost is literally what ChatGPT wa...</td>\n",
       "      <td>Efrayl</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11r0qx0</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>API Throttling (not rate limit)</td>\n",
       "      <td>I swear to god this is happening. I've been re...</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-03-14 12:33:17</td>\n",
       "      <td>DocmodApp</td>\n",
       "      <td>2</td>\n",
       "      <td>rate limit</td>\n",
       "      <td>API Throttling (not rate limit) I swear to god...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1hgna9l</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Google has overshadowed 12 days of open ai til...</td>\n",
       "      <td>The response open ai would have expected from ...</td>\n",
       "      <td>243</td>\n",
       "      <td>2024-12-18 02:55:27</td>\n",
       "      <td>No_Macaroon_7608</td>\n",
       "      <td>15</td>\n",
       "      <td>Sora</td>\n",
       "      <td>Google was so bad I thought did they get AI sc...</td>\n",
       "      <td>m2kzjk0</td>\n",
       "      <td>Google was so bad I thought did they get AI sc...</td>\n",
       "      <td>mike7seven</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11dto2l</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Could Chat GPT create a pdf that has non-stand...</td>\n",
       "      <td>Hi, I am reviewing a pdf and when I changed th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-28 05:55:34</td>\n",
       "      <td>Few_Mathematician_13</td>\n",
       "      <td>0</td>\n",
       "      <td>ChatGPT review</td>\n",
       "      <td>Could Chat GPT create a pdf that has non-stand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id subreddit                                         post_title  \\\n",
       "1  1icahc2   ChatGPT      Why does deepseek keep calling itself chatgpt   \n",
       "2  1ib7xft   ChatGPT  Please bro stop using the free better alternat...   \n",
       "3  11r0qx0    OpenAI                    API Throttling (not rate limit)   \n",
       "4  1hgna9l    OpenAI  Google has overshadowed 12 days of open ai til...   \n",
       "5  11dto2l    OpenAI  Could Chat GPT create a pdf that has non-stand...   \n",
       "\n",
       "                                           post_body  number_of_comments  \\\n",
       "1            well I know identity doesn’t matter,                    116   \n",
       "2                                                NaN                 860   \n",
       "3  I swear to god this is happening. I've been re...                   5   \n",
       "4  The response open ai would have expected from ...                 243   \n",
       "5  Hi, I am reviewing a pdf and when I changed th...                   0   \n",
       "\n",
       "     readable_datetime           post_author  number_of_upvotes  \\\n",
       "1  2025-01-28 23:50:33      baskerville_clan                166   \n",
       "2  2025-01-27 16:40:08      analgerianabroad                124   \n",
       "3  2023-03-14 12:33:17             DocmodApp                  2   \n",
       "4  2024-12-18 02:55:27      No_Macaroon_7608                 15   \n",
       "5  2023-02-28 05:55:34  Few_Mathematician_13                  0   \n",
       "\n",
       "            query                                               text  \\\n",
       "1             NaN  Why does deepseek keep calling itself chatgpt ...   \n",
       "2             NaN  \"Faking\" low cost is literally what ChatGPT wa...   \n",
       "3      rate limit  API Throttling (not rate limit) I swear to god...   \n",
       "4            Sora  Google was so bad I thought did they get AI sc...   \n",
       "5  ChatGPT review  Could Chat GPT create a pdf that has non-stand...   \n",
       "\n",
       "  comment_id                                       comment_body  \\\n",
       "1        NaN                                                NaN   \n",
       "2    m9h65nu  \"Faking\" low cost is literally what ChatGPT wa...   \n",
       "3        NaN                                                NaN   \n",
       "4    m2kzjk0  Google was so bad I thought did they get AI sc...   \n",
       "5        NaN                                                NaN   \n",
       "\n",
       "  comment_author  m_label_1  \n",
       "1            NaN        0.0  \n",
       "2         Efrayl       -1.0  \n",
       "3            NaN       -1.0  \n",
       "4     mike7seven       -1.0  \n",
       "5            NaN        0.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_manual_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the old_manual_label to a new csv file\n",
    "old_manual_label.to_csv(r'..\\Data\\Labelling\\Manual\\manual_val_test_set_tfidf.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
