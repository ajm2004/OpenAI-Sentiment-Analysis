{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABELLING - ACTIVE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (4.48.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jonathan\\desktop\\f20aa - applied text analytics\\cw1\\f20aa_grp5\\.venv\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Labelling and Finetuning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function that labels the data with the provided model\n",
    "and saves the labeled data to a csv file. Additionally,\n",
    "it saves 100 rows with the lowest RoBERTa confidence scores\n",
    "to a new CSV file.\n",
    "\n",
    "Params:\n",
    "model - the model to be used for sentiment analysis\n",
    "tokenizer - the tokenizer to be used for sentiment analysis\n",
    "df - dataframe with the text column to be labeled\n",
    "round - active learning round\n",
    "'''\n",
    "def label_data(model, tokenizer, df, round):\n",
    "  # Initialize the sentiment analysis pipeline\n",
    "  sentiment_pipeline = pipeline(\"text-classification\", \n",
    "                                model=model,\n",
    "                                tokenizer=tokenizer,\n",
    "                                device=0) \n",
    "  \n",
    "  # Extract the text column of selected_data as a list\n",
    "  reviews = df[\"text\"].tolist()\n",
    "    \n",
    "  # Calculate the sentiment of the each of the reviews\n",
    "  print(\"Active Learning - Automated Labelling - Round \", round)\n",
    "  print(\"Predicting sentiment labels of data...\")\n",
    "\n",
    "  kwargs = {'padding':True,'truncation':True,'max_length':512}\n",
    "  results = sentiment_pipeline(reviews, **kwargs) \n",
    "\n",
    "  print(\"Sentiment labels predicted.\")\n",
    "  print(\"Saving labeled data to a csv files...\")\n",
    "\n",
    "  # Add the sentiment and score to the selected_data DataFrame\n",
    "  label2id = {\"positive\": 1, \"negative\": -1, \"neutral\": 0}\n",
    "  df[\"roberta_label\"] = [label2id[res[\"label\"]] for res in results]\n",
    "  df[\"roberta_score\"] = [res[\"score\"] for res in results]\n",
    "\n",
    "  # Save the labeled data to a csv file\n",
    "  df.to_csv(f'../Data/Labelling/round{round}_roberta_labelled_all_data.csv', index=False)\n",
    "\n",
    "  # Save 100 rows with the lowest RoBERTa confidence scores to a new CSV file\n",
    "  df_low_confidence = df.nsmallest(100, 'roberta_score')\n",
    "  df_low_confidence.to_csv(f'../Data/Labelling/round{round}_roberta_labelled_low_confidence.csv', index=False)\n",
    "  \n",
    "  print(f\"Completed Round {round} - Automated Labeling\")\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(model, train_data):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Active Learning Based Labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Active learning allows us to manually label the most informative parts of the dataset that confuses the model the most. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 1 - Use pretrained sentiment analysis Transformer model for automated labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "selected_data = pd.read_csv('../Data/selected_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained model, tokenizer, and configuration from Hugging Face\n",
    "pretrained_model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active Learning - Automated Labelling - Round  1\n",
      "Predicting sentiment labels of data...\n",
      "Sentiment labels predicted.\n",
      "Saving labeled data to a csv files...\n",
      "Completed Round 1 - Automated Labeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonathan\\AppData\\Local\\Temp\\ipykernel_12052\\177041109.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"roberta_label\"] = [label2id[res[\"label\"]] for res in results]\n",
      "C:\\Users\\Jonathan\\AppData\\Local\\Temp\\ipykernel_12052\\177041109.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"roberta_score\"] = [res[\"score\"] for res in results]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_body</th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>readable_datetime</th>\n",
       "      <th>post_author</th>\n",
       "      <th>number_of_upvotes</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>roberta_label</th>\n",
       "      <th>roberta_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1d31lxf</td>\n",
       "      <td>technology</td>\n",
       "      <td>Former OpenAI board member explains why they f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "      <td>2024-05-29 06:31:18</td>\n",
       "      <td>Maxie445</td>\n",
       "      <td>84</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Good luck to the consumers/customers who are t...</td>\n",
       "      <td>l64i9ts</td>\n",
       "      <td>Good luck to the consumers/customers who are t...</td>\n",
       "      <td>imaketrollfaces</td>\n",
       "      <td>0.717946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1dn7dwq</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>I’m sick of waiting for chatGPT 4o Voice and I...</td>\n",
       "      <td>I’ve been religiously checking for the voice u...</td>\n",
       "      <td>368</td>\n",
       "      <td>2024-06-24 11:02:41</td>\n",
       "      <td>surfer808</td>\n",
       "      <td>45</td>\n",
       "      <td>ChatGPT vs Claude</td>\n",
       "      <td>OpenAI did a great job of showing the public t...</td>\n",
       "      <td>la0rsb1</td>\n",
       "      <td>OpenAI did a great job of showing the public t...</td>\n",
       "      <td>q_freak</td>\n",
       "      <td>0.710471</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1hiru1c</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>OpenAI's new model is equivalent to the 175th ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114</td>\n",
       "      <td>2024-12-20 23:38:56</td>\n",
       "      <td>MetaKnowing</td>\n",
       "      <td>236</td>\n",
       "      <td>o3</td>\n",
       "      <td>OpenAI's new model is equivalent to the 175th ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708699</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id   subreddit                                         post_title  \\\n",
       "0  1d31lxf  technology  Former OpenAI board member explains why they f...   \n",
       "1  1dn7dwq      OpenAI  I’m sick of waiting for chatGPT 4o Voice and I...   \n",
       "2  1hiru1c     ChatGPT  OpenAI's new model is equivalent to the 175th ...   \n",
       "\n",
       "                                           post_body  number_of_comments  \\\n",
       "0                                                NaN                  97   \n",
       "1  I’ve been religiously checking for the voice u...                 368   \n",
       "2                                                NaN                 114   \n",
       "\n",
       "     readable_datetime  post_author  number_of_upvotes              query  \\\n",
       "0  2024-05-29 06:31:18     Maxie445                 84             OpenAI   \n",
       "1  2024-06-24 11:02:41    surfer808                 45  ChatGPT vs Claude   \n",
       "2  2024-12-20 23:38:56  MetaKnowing                236                 o3   \n",
       "\n",
       "                                                text comment_id  \\\n",
       "0  Good luck to the consumers/customers who are t...    l64i9ts   \n",
       "1  OpenAI did a great job of showing the public t...    la0rsb1   \n",
       "2  OpenAI's new model is equivalent to the 175th ...        NaN   \n",
       "\n",
       "                                        comment_body   comment_author  \\\n",
       "0  Good luck to the consumers/customers who are t...  imaketrollfaces   \n",
       "1  OpenAI did a great job of showing the public t...          q_freak   \n",
       "2                                                NaN              NaN   \n",
       "\n",
       "   cosine_similarity  roberta_label  roberta_score  \n",
       "0           0.717946              1       0.931254  \n",
       "1           0.710471              1       0.950637  \n",
       "2           0.708699              1       0.947382  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data(model = model, \n",
    "           df = selected_data, \n",
    "           tokenizer = tokenizer,\n",
    "           round = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
