{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: textblob in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.9->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.9->textblob) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.9->textblob) (4.66.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (4.66.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.41.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: emoji in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.14.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "zsh:1: command not found: python\n"
     ]
    }
   ],
   "source": [
    "%pip install contractions\n",
    "%pip install textblob\n",
    "%pip install nltk\n",
    "%pip install scikit-learn\n",
    "%pip install transformers\n",
    "%pip install emoji\n",
    "%pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction import text\n",
    "import string\n",
    "import contractions\n",
    "import emoji\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mj/x2186rjd6njg5v_9jd7x61kh0000gn/T/ipykernel_3929/2371751024.py:1: DtypeWarning: Columns (5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"combined_data.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_time</th>\n",
       "      <th>author</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1hr4hc6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Weekly Self-Promotional Mega Thread 49, 01.01....</td>\n",
       "      <td>All the self-promotional posts about your AI p...</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>23</td>\n",
       "      <td>118</td>\n",
       "      <td>2025-01-01 14:58:15</td>\n",
       "      <td>pirate_jack_sparrow_</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ggixzy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMA with OpenAI’s Sam Altman, Kevin Weil, Srin...</td>\n",
       "      <td>Consider this AMA our Reddit launch.\\n\\nAsk us...</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>4000</td>\n",
       "      <td>4705</td>\n",
       "      <td>2024-10-31 16:40:38</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1id5l47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OpenAI Pleads That It Can’t Make Money Without...</td>\n",
       "      <td># \"It would be impossible to train today’s lea...</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>1135</td>\n",
       "      <td>182</td>\n",
       "      <td>2025-01-29 21:45:58</td>\n",
       "      <td>faustoc5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1icyjx6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remember When OpenAI Threatened Your Job? A Fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>1222</td>\n",
       "      <td>131</td>\n",
       "      <td>2025-01-29 16:59:46</td>\n",
       "      <td>Dexter01010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1icvvjq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"My AI just absolutely roasted me and I'm ques...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>1362</td>\n",
       "      <td>159</td>\n",
       "      <td>2025-01-29 15:08:12</td>\n",
       "      <td>maruhadapurpurine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id comment_id                                              title  \\\n",
       "0  1hr4hc6        NaN  Weekly Self-Promotional Mega Thread 49, 01.01....   \n",
       "1  1ggixzy        NaN  AMA with OpenAI’s Sam Altman, Kevin Weil, Srin...   \n",
       "2  1id5l47        NaN  OpenAI Pleads That It Can’t Make Money Without...   \n",
       "3  1icyjx6        NaN  Remember When OpenAI Threatened Your Job? A Fr...   \n",
       "4  1icvvjq        NaN  \"My AI just absolutely roasted me and I'm ques...   \n",
       "\n",
       "                                                body subreddit upvotes  \\\n",
       "0  All the self-promotional posts about your AI p...   ChatGPT      23   \n",
       "1  Consider this AMA our Reddit launch.\\n\\nAsk us...   ChatGPT    4000   \n",
       "2  # \"It would be impossible to train today’s lea...   ChatGPT    1135   \n",
       "3                                                NaN   ChatGPT    1222   \n",
       "4                                                NaN   ChatGPT    1362   \n",
       "\n",
       "  comments            date_time                author query  \n",
       "0      118  2025-01-01 14:58:15  pirate_jack_sparrow_   NaN  \n",
       "1     4705  2024-10-31 16:40:38                OpenAI   NaN  \n",
       "2      182  2025-01-29 21:45:58              faustoc5   NaN  \n",
       "3      131  2025-01-29 16:59:46           Dexter01010   NaN  \n",
       "4      159  2025-01-29 15:08:12     maruhadapurpurine   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"combined_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Weekly Self-Promotional Mega Thread 49, 01.01....\n",
       "1    AMA with OpenAI’s Sam Altman, Kevin Weil, Srin...\n",
       "2    OpenAI Pleads That It Can’t Make Money Without...\n",
       "3    Remember When OpenAI Threatened Your Job? A Fr...\n",
       "4    \"My AI just absolutely roasted me and I'm ques...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"] = data.apply(lambda row: f\"{row['title']} {row['body']}\" if pd.isna(row['comment_id']) else row['body'], axis=1)\n",
    "data[\"text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing blank rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_time</th>\n",
       "      <th>author</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1hr4hc6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Weekly Self-Promotional Mega Thread 49, 01.01....</td>\n",
       "      <td>All the self-promotional posts about your AI p...</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>23</td>\n",
       "      <td>118</td>\n",
       "      <td>2025-01-01 14:58:15</td>\n",
       "      <td>pirate_jack_sparrow_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Weekly Self-Promotional Mega Thread 49, 01.01....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ggixzy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMA with OpenAI’s Sam Altman, Kevin Weil, Srin...</td>\n",
       "      <td>Consider this AMA our Reddit launch.\\n\\nAsk us...</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>4000</td>\n",
       "      <td>4705</td>\n",
       "      <td>2024-10-31 16:40:38</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMA with OpenAI’s Sam Altman, Kevin Weil, Srin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1id5l47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OpenAI Pleads That It Can’t Make Money Without...</td>\n",
       "      <td># \"It would be impossible to train today’s lea...</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>1135</td>\n",
       "      <td>182</td>\n",
       "      <td>2025-01-29 21:45:58</td>\n",
       "      <td>faustoc5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OpenAI Pleads That It Can’t Make Money Without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1icyjx6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remember When OpenAI Threatened Your Job? A Fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>1222</td>\n",
       "      <td>131</td>\n",
       "      <td>2025-01-29 16:59:46</td>\n",
       "      <td>Dexter01010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remember When OpenAI Threatened Your Job? A Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1icvvjq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"My AI just absolutely roasted me and I'm ques...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>1362</td>\n",
       "      <td>159</td>\n",
       "      <td>2025-01-29 15:08:12</td>\n",
       "      <td>maruhadapurpurine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"My AI just absolutely roasted me and I'm ques...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id comment_id                                              title  \\\n",
       "0  1hr4hc6        NaN  Weekly Self-Promotional Mega Thread 49, 01.01....   \n",
       "1  1ggixzy        NaN  AMA with OpenAI’s Sam Altman, Kevin Weil, Srin...   \n",
       "2  1id5l47        NaN  OpenAI Pleads That It Can’t Make Money Without...   \n",
       "3  1icyjx6        NaN  Remember When OpenAI Threatened Your Job? A Fr...   \n",
       "4  1icvvjq        NaN  \"My AI just absolutely roasted me and I'm ques...   \n",
       "\n",
       "                                                body subreddit upvotes  \\\n",
       "0  All the self-promotional posts about your AI p...   ChatGPT      23   \n",
       "1  Consider this AMA our Reddit launch.\\n\\nAsk us...   ChatGPT    4000   \n",
       "2  # \"It would be impossible to train today’s lea...   ChatGPT    1135   \n",
       "3                                                NaN   ChatGPT    1222   \n",
       "4                                                NaN   ChatGPT    1362   \n",
       "\n",
       "  comments            date_time                author query  \\\n",
       "0      118  2025-01-01 14:58:15  pirate_jack_sparrow_   NaN   \n",
       "1     4705  2024-10-31 16:40:38                OpenAI   NaN   \n",
       "2      182  2025-01-29 21:45:58              faustoc5   NaN   \n",
       "3      131  2025-01-29 16:59:46           Dexter01010   NaN   \n",
       "4      159  2025-01-29 15:08:12     maruhadapurpurine   NaN   \n",
       "\n",
       "                                                text  \n",
       "0  Weekly Self-Promotional Mega Thread 49, 01.01....  \n",
       "1  AMA with OpenAI’s Sam Altman, Kevin Weil, Srin...  \n",
       "2  OpenAI Pleads That It Can’t Make Money Without...  \n",
       "3  Remember When OpenAI Threatened Your Job? A Fr...  \n",
       "4  \"My AI just absolutely roasted me and I'm ques...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Blank Rows\n",
    "data = data.dropna(subset=[\"text\"])\n",
    "data = data.reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting texts to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    weekly self-promotional mega thread 49, 01.01....\n",
       "1    ama with openai’s sam altman, kevin weil, srin...\n",
       "2    openai pleads that it can’t make money without...\n",
       "3    remember when openai threatened your job? a fr...\n",
       "4    \"my ai just absolutely roasted me and i'm ques...\n",
       "Name: Cleaned Text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase\n",
    "def lower(text):\n",
    "  return text.lower()\n",
    "\n",
    "data[\"Cleaned Text\"] = data[\"text\"].apply(lower)\n",
    "data[\"Cleaned Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing r/, usernames, new line indicators, and links from texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    weekly self-promotional mega thread 49, 01.01....\n",
       "1    ama with openai’s sam altman, kevin weil, srin...\n",
       "2    openai pleads that it can’t make money without...\n",
       "3    remember when openai threatened your job? a fr...\n",
       "4    \"my ai just absolutely roasted me and i'm ques...\n",
       "Name: Cleaned Text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unnecessary tokens\n",
    "def remove_links(text):\n",
    "  return re.sub(r'http[s]?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "def remove_user_mentions(text):\n",
    "    return re.sub(r'u/\\S+', '', text)\n",
    "\n",
    "data[\"Cleaned Text\"] = data[\"Cleaned Text\"].str.replace('r/', '', regex=False)\n",
    "data[\"Cleaned Text\"] = data[\"Cleaned Text\"].str.replace(\"\\n\\n\", ' ', regex=False)\n",
    "data[\"Cleaned Text\"] = data[\"Cleaned Text\"].apply(remove_links)\n",
    "data[\"Cleaned Text\"] = data[\"Cleaned Text\"].apply(remove_user_mentions)\n",
    "\n",
    "data[\"Cleaned Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing spelling errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fix spelling\n",
    "# def correct_spelling(text):\n",
    "#     return str(TextBlob(text).correct())\n",
    "\n",
    "# data[\"Cleaned Text\"] = data[\"Cleaned Text\"].apply(correct_spelling)\n",
    "# data[\"Cleaned Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanding contractions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    weekly self-promotional mega thread 49, 01.01....\n",
       "1    ama with openai’s sam altman, kevin weil, srin...\n",
       "2    openai pleads that it cannot make money withou...\n",
       "3    remember when openai threatened your job? a fr...\n",
       "4    \"my ai just absolutely roasted me and i am que...\n",
       "Name: Cleaned Text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand contractions\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "data[\"Cleaned Text\"] = data[\"Cleaned Text\"].apply(expand_contractions)\n",
    "data[\"Cleaned Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    weekly self-promotional mega thread 49, 01.01....\n",
       "1    ama openai’s sam altman, kevin weil, srinivas ...\n",
       "2    openai pleads make money using copyrighted mat...\n",
       "3    remember openai threatened job? free ai just r...\n",
       "4    \"my ai just absolutely roasted questioning rea...\n",
       "Name: Cleaned Text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "stopwords = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "data[\"Cleaned Text\"] = data[\"Cleaned Text\"].apply(\n",
    "    lambda text: ' '.join([word for word in text.split() if word.lower() not in stopwords])\n",
    ")\n",
    "data[\"Cleaned Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    weekly self promotional mega thread 49 01 01 2...\n",
       "1    ama openai’s sam altman kevin weil srinivas na...\n",
       "2    openai pleads make money using copyrighted mat...\n",
       "3    remember openai threatened job free ai just re...\n",
       "4    my ai just absolutely roasted questioning real...\n",
       "Name: Cleaned Text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuations\n",
    "def remove_punctuations(text):\n",
    "    text = re.sub(r'[-]', ' ', text)\n",
    "    text = re.sub(r'(\\S)[' + re.escape(string.punctuation) + r'](\\S)', r'\\1 \\2', text)\n",
    "    return text\n",
    "\n",
    "data[\"Cleaned Text\"] = data[\"Cleaned Text\"].apply(remove_punctuations)\n",
    "\n",
    "pattern_punctuations = r'[' + string.punctuation + r']'\n",
    "\n",
    "data[\"Cleaned Text\"] = data[\"Cleaned Text\"].str.replace(pattern_punctuations, '', regex=True)\n",
    "\n",
    "data[\"Cleaned Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting emojis to their descriptive names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    weekly self promotional mega thread 49 01 01 2...\n",
       "1    ama openai’s sam altman kevin weil srinivas na...\n",
       "2    openai pleads make money using copyrighted mat...\n",
       "3    remember openai threatened job free ai just re...\n",
       "4    my ai just absolutely roasted questioning real...\n",
       "Name: Cleaned Text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def convert_emojis(text):\n",
    "   return emoji.demojize(text)\n",
    "\n",
    "data[\"Cleaned Text\"] = data[\"Cleaned Text\"].apply(convert_emojis)\n",
    "data[\"Cleaned Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "    for ent in doc.ents:\n",
    "        tokens.append(ent.text)\n",
    "\n",
    "    non_entity_tokens = [token.text for token in doc if not token.ent_type_ and not token.is_punct and not token.is_space]\n",
    "    tokens.extend(non_entity_tokens)\n",
    "    return tokens\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=custom_tokenizer,\n",
    "    use_idf=False\n",
    ")\n",
    "\n",
    "doc_vectors = vectorizer.fit_transform(data[\"Cleaned Text\"])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "dense_vec = doc_vectors.todense()\n",
    "dense_list = dense_vec.tolist()\n",
    "tfidf_data = pd.DataFrame(dense_list, columns=feature_names)\n",
    "tfidf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\"Discussions about ChatGPT, its performance, user experiences, applications, limitations, ethical concerns, and comparisons with other AI models developed by OpenAI.\"]\n",
    "\n",
    "idf_vectorizer = TfidfVectorizer(\n",
    "    tokenizer=custom_tokenizer,\n",
    "    use_idf=True,\n",
    "    # turn off sublinear_tf to get the same results as the previous implementation\n",
    "    sublinear_tf=False\n",
    ")\n",
    "\n",
    "idf_vectorizer.fit(data[\"Cleaned Text\"])\n",
    "query_vector = idf_vectorizer.transform([query])\n",
    "\n",
    "similarity_scores = cosine_similarity(query_vector, doc_vectors)[0]\n",
    "\n",
    "data[\"similarity\"] = similarity_scores\n",
    "\n",
    "sorted_data = data.sort_values(by=\"similarity\", ascending=False)\n",
    "\n",
    "sorted_data.to_csv(\"similarity_scores.csv\", index=False)\n",
    "\n",
    "print(\"Data saved to 'similarity_scores.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
